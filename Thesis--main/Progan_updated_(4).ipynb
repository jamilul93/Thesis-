{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "fzSeOLTqscoI",
        "outputId": "80b8fa3b-9bba-42b8-97ab-57fabdaf81d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0f6d3514c078>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jVgXifE0iUG",
        "outputId": "a59f41a1-9b23-4fea-e435-96a1908a48fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the dataset path\n",
        "# Replace 'your_dataset_folder_path' with the actual path of your dataset in Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/Train-20240208T094256Z-001'\n"
      ],
      "metadata": {
        "id": "zKMn7hBmsojM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Get the directory path\n",
        "folder_path = \"/content/drive/MyDrive/Train-20240208T094256Z-001/Train\"\n",
        "\n",
        "# Count the number of images in the folder\n",
        "image_count = 0\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "        image_count += 1\n",
        "\n",
        "# Print the number of images\n",
        "print(f\"Number of images in the folder: {image_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEklYjQr1jLG",
        "outputId": "91ebfd26-c8b9-4e3e-9f96-a6f8c993e3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the folder: 5027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from math import log2\n",
        "\n",
        "START_TRAIN_AT_IMG_SIZE = 256\n",
        "DATASET =dataset_path\n",
        "CHECKPOINT_GEN = \"generator.pth\"\n",
        "CHECKPOINT_CRITIC =\"critic.pth\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SAVE_MODEL = True\n",
        "LOAD_MODEL = False\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZES = [32, 32, 32, 16, 16, 16, 16, 8, 4]\n",
        "CHANNELS_IMG = 3\n",
        "Z_DIM =100 # should be 512 in original paper\n",
        "IN_CHANNELS =256 # should be 512 in original paper\n",
        "CRITIC_ITERATIONS = 1\n",
        "LAMBDA_GP = 10\n",
        "PROGRESSIVE_EPOCHS = [30] * len(BATCH_SIZES)\n",
        "FIXED_NOISE = torch.randn(8, Z_DIM, 1, 1).to(DEVICE)\n",
        "NUM_WORKERS = 4"
      ],
      "metadata": {
        "id": "kYVUHq2Gsrpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementation of ProGAN generator and discriminator with the key\n",
        "attributions from the paper. We have tried to make the implementation\n",
        "compact but a goal is also to keep it readable and understandable.\n",
        "Specifically the key points implemented are:\n",
        "\n",
        "1) Progressive growing (of model and layers)\n",
        "2) Minibatch std on Discriminator\n",
        "3) Normalization with PixelNorm\n",
        "4) Equalized Learning Rate (here I cheated and only did it on Conv layers)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from math import log2\n",
        "\n",
        "\"\"\"\n",
        "Factors is used in Discrmininator and Generator for how much\n",
        "the channels should be multiplied and expanded for each layer,\n",
        "so specifically the first 5 layers the channels stay the same,\n",
        "whereas when we increase the img_size (towards the later layers)\n",
        "we decrease the number of chanels by 1/2, 1/4, etc.\n",
        "\"\"\"\n",
        "factors = [1, 1, 1, 1, 1 / 2, 1 / 4, 1 / 8, 1 / 16, 1 / 32]\n",
        "\n",
        "\n",
        "class WSConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Weight scaled Conv2d (Equalized Learning Rate)\n",
        "    Note that input is multiplied rather than changing weights\n",
        "    this will have the same result.\n",
        "\n",
        "    Inspired and looked at:\n",
        "    https://github.com/nvnbny/progressive_growing_of_gans/blob/master/modelUtils.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2\n",
        "    ):\n",
        "        super(WSConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.scale = (gain / (in_channels * (kernel_size ** 2))) ** 0.5\n",
        "        self.bias = self.conv.bias\n",
        "        self.conv.bias = None\n",
        "\n",
        "        # initialize conv layer\n",
        "        nn.init.normal_(self.conv.weight)\n",
        "        nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
        "\n",
        "\n",
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PixelNorm, self).__init__()\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, use_pixelnorm=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.use_pn = use_pixelnorm\n",
        "        self.conv1 = WSConv2d(in_channels, out_channels)\n",
        "        self.conv2 = WSConv2d(out_channels, out_channels)\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "        self.pn = PixelNorm()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky(self.conv1(x))\n",
        "        x = self.pn(x) if self.use_pn else x\n",
        "        x = self.leaky(self.conv2(x))\n",
        "        x = self.pn(x) if self.use_pn else x\n",
        "        return x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, in_channels, img_channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # initial takes 1x1 -> 4x4\n",
        "        self.initial = nn.Sequential(\n",
        "            PixelNorm(),\n",
        "            nn.ConvTranspose2d(z_dim, in_channels, 4, 4, 0),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            WSConv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            PixelNorm(),\n",
        "        )\n",
        "\n",
        "        self.initial_rgb = WSConv2d(\n",
        "            in_channels, img_channels, kernel_size=1, stride=1, padding=0\n",
        "        )\n",
        "        self.prog_blocks, self.rgb_layers = (\n",
        "            nn.ModuleList([]),\n",
        "            nn.ModuleList([self.initial_rgb]),\n",
        "        )\n",
        "\n",
        "        for i in range(\n",
        "            len(factors) - 1\n",
        "        ):  # -1 to prevent index error because of factors[i+1]\n",
        "            conv_in_c = int(in_channels * factors[i])\n",
        "            conv_out_c = int(in_channels * factors[i + 1])\n",
        "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
        "            self.rgb_layers.append(\n",
        "                WSConv2d(conv_out_c, img_channels, kernel_size=1, stride=1, padding=0)\n",
        "            )\n",
        "\n",
        "    def fade_in(self, alpha, upscaled, generated):\n",
        "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
        "        return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
        "\n",
        "    def forward(self, x, alpha, steps):\n",
        "        out = self.initial(x)\n",
        "\n",
        "        if steps == 0:\n",
        "            return self.initial_rgb(out)\n",
        "\n",
        "        for step in range(steps):\n",
        "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
        "            out = self.prog_blocks[step](upscaled)\n",
        "\n",
        "        # The number of channels in upscale will stay the same, while\n",
        "        # out which has moved through prog_blocks might change. To ensure\n",
        "        # we can convert both to rgb we use different rgb_layers\n",
        "        # (steps-1) and steps for upscaled, out respectively\n",
        "        final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
        "        final_out = self.rgb_layers[steps](out)\n",
        "        return self.fade_in(alpha, final_upscaled, final_out)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, z_dim, in_channels, img_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.prog_blocks, self.rgb_layers = nn.ModuleList([]), nn.ModuleList([])\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "\n",
        "        # here we work back ways from factors because the discriminator\n",
        "        # should be mirrored from the generator. So the first prog_block and\n",
        "        # rgb layer we append will work for input size 1024x1024, then 512->256-> etc\n",
        "        for i in range(len(factors) - 1, 0, -1):\n",
        "            conv_in = int(in_channels * factors[i])\n",
        "            conv_out = int(in_channels * factors[i - 1])\n",
        "            self.prog_blocks.append(ConvBlock(conv_in, conv_out, use_pixelnorm=False))\n",
        "            self.rgb_layers.append(\n",
        "                WSConv2d(img_channels, conv_in, kernel_size=1, stride=1, padding=0)\n",
        "            )\n",
        "\n",
        "        # perhaps confusing name \"initial_rgb\" this is just the RGB layer for 4x4 input size\n",
        "        # did this to \"mirror\" the generator initial_rgb\n",
        "        self.initial_rgb = WSConv2d(\n",
        "            img_channels, in_channels, kernel_size=1, stride=1, padding=0\n",
        "        )\n",
        "        self.rgb_layers.append(self.initial_rgb)\n",
        "        self.avg_pool = nn.AvgPool2d(\n",
        "            kernel_size=2, stride=2\n",
        "        )  # down sampling using avg pool\n",
        "\n",
        "        # this is the block for 4x4 input size\n",
        "        self.final_block = nn.Sequential(\n",
        "            # +1 to in_channels because we concatenate from MiniBatch std\n",
        "            WSConv2d(in_channels + 1, in_channels, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            WSConv2d(in_channels, in_channels, kernel_size=4, padding=0, stride=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            WSConv2d(\n",
        "                in_channels, 1, kernel_size=1, padding=0, stride=1\n",
        "            ),  # we use this instead of linear layer\n",
        "        )\n",
        "\n",
        "    def fade_in(self, alpha, downscaled, out):\n",
        "        \"\"\"Used to fade in downscaled using avg pooling and output from CNN\"\"\"\n",
        "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
        "        return alpha * out + (1 - alpha) * downscaled\n",
        "\n",
        "    def minibatch_std(self, x):\n",
        "        batch_statistics = (\n",
        "            torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
        "        )\n",
        "        # we take the std for each example (across all channels, and pixels) then we repeat it\n",
        "        # for a single channel and concatenate it with the image. In this way the discriminator\n",
        "        # will get information about the variation in the batch/image\n",
        "        return torch.cat([x, batch_statistics], dim=1)\n",
        "\n",
        "    def forward(self, x, alpha, steps):\n",
        "        # where we should start in the list of prog_blocks, maybe a bit confusing but\n",
        "        # the last is for the 4x4. So example let's say steps=1, then we should start\n",
        "        # at the second to last because input_size will be 8x8. If steps==0 we just\n",
        "        # use the final block\n",
        "        cur_step = len(self.prog_blocks) - steps\n",
        "\n",
        "        # convert from rgb as initial step, this will depend on\n",
        "        # the image size (each will have it's on rgb layer)\n",
        "        out = self.leaky(self.rgb_layers[cur_step](x))\n",
        "\n",
        "        if steps == 0:  # i.e, image is 4x4\n",
        "            out = self.minibatch_std(out)\n",
        "            return self.final_block(out).view(out.shape[0], -1)\n",
        "\n",
        "        # because prog_blocks might change the channels, for down scale we use rgb_layer\n",
        "        # from previous/smaller size which in our case correlates to +1 in the indexing\n",
        "        downscaled = self.leaky(self.rgb_layers[cur_step + 1](self.avg_pool(x)))\n",
        "        out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
        "\n",
        "        # the fade_in is done first between the downscaled and the input\n",
        "        # this is opposite from the generator\n",
        "        out = self.fade_in(alpha, downscaled, out)\n",
        "\n",
        "        for step in range(cur_step + 1, len(self.prog_blocks)):\n",
        "            out = self.prog_blocks[step](out)\n",
        "            out = self.avg_pool(out)\n",
        "\n",
        "        out = self.minibatch_std(out)\n",
        "        return self.final_block(out).view(out.shape[0], -1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Z_DIM =100\n",
        "    IN_CHANNELS =256\n",
        "    gen = Generator(Z_DIM, IN_CHANNELS, img_channels=3)\n",
        "    critic = Discriminator(Z_DIM, IN_CHANNELS, img_channels=3)\n",
        "\n",
        "    for img_size in [4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
        "        num_steps = int(log2(img_size / 4))\n",
        "        x = torch.randn((1, Z_DIM, 1, 1))\n",
        "        z = gen(x, 0.5, steps=num_steps)\n",
        "        assert z.shape == (1, 3, img_size, img_size)\n",
        "        out = critic(z, alpha=0.5, steps=num_steps)\n",
        "        assert out.shape == (1, 1)\n",
        "        print(f\"Success! At img size: {img_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6zGNSNIs89m",
        "outputId": "5aa5d167-3b44-4695-f5b3-6d49bec29ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! At img size: 4\n",
            "Success! At img size: 8\n",
            "Success! At img size: 16\n",
            "Success! At img size: 32\n",
            "Success! At img size: 64\n",
            "Success! At img size: 128\n",
            "Success! At img size: 256\n",
            "Success! At img size: 512\n",
            "Success! At img size: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "from scipy.stats import truncnorm\n",
        "\n",
        "# Print losses occasionally and print to tensorboard\n",
        "def plot_to_tensorboard(\n",
        "    writer, loss_critic, loss_gen, real, fake, tensorboard_step\n",
        "):\n",
        "    writer.add_scalar(\"Loss Critic\", loss_critic, global_step=tensorboard_step)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # take out (up to) 8 examples to plot\n",
        "        img_grid_real = torchvision.utils.make_grid(real[:8], normalize=True)\n",
        "        img_grid_fake = torchvision.utils.make_grid(fake[:8], normalize=True)\n",
        "        writer.add_image(\"Real\", img_grid_real, global_step=tensorboard_step)\n",
        "        writer.add_image(\"Fake\", img_grid_fake, global_step=tensorboard_step)\n",
        "\n",
        "\n",
        "def gradient_penalty(critic, real, fake, alpha, train_step, device=\"cpu\"):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
        "    interpolated_images.requires_grad_(True)\n",
        "\n",
        "    # Calculate critic scores\n",
        "    mixed_scores = critic(interpolated_images, alpha, train_step)\n",
        "\n",
        "    # Take the gradient of the scores with respect to the images\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=interpolated_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=\"cuda\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def generate_examples(gen, steps, truncation=0.7, n=100):\n",
        "    \"\"\"\n",
        "    Tried using truncation trick here but not sure it actually helped anything, you can\n",
        "    remove it if you like and just sample from torch.randn\n",
        "    \"\"\"\n",
        "    gen.eval()\n",
        "    alpha = 1.0\n",
        "    for i in range(n):\n",
        "        with torch.no_grad():\n",
        "            noise = torch.tensor(truncnorm.rvs(-truncation, truncation, size=(1, Z_DIM, 1, 1)), device=DEVICE, dtype=torch.float32)\n",
        "            img = gen(noise, alpha, steps)\n",
        "            save_image(img*0.5+0.5, f\"saved_examples/img_{i}.png\")\n",
        "    gen.train()"
      ],
      "metadata": {
        "id": "0hDKpCj9tSKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.utils as vutils\n",
        "import torch # Assuming torch is already imported\n",
        "\n",
        "def save_generated_images(epoch, generator, fixed_noise, save_dir, step):\n",
        "    with torch.no_grad():\n",
        "        # Generate images\n",
        "        generated_images = generator(fixed_noise, 1, step).detach().cpu()\n",
        "\n",
        "        # Ensure save directory exists\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        # Iterate over each image\n",
        "        for i, image in enumerate(generated_images):\n",
        "            # Convert image to numpy format\n",
        "            image = np.transpose(image, (1,2,0))\n",
        "            image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0,1]\n",
        "\n",
        "            plt.figure(figsize=(8, 8))\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Save each image individually\n",
        "            save_path = os.path.join(save_dir, f'epoch_{epoch}_step_{step}_image_{i}.png')\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "SzV6RG1FtZNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Training of ProGAN using WGAN-GP loss\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from math import log2\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmarks = True\n",
        "\n",
        "sav_dir='/content/drive/MyDrive/output'\n",
        "\n",
        "def get_loader(image_size):\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.Normalize(\n",
        "                [0.5 for _ in range(CHANNELS_IMG)],\n",
        "                [0.5 for _ in range(CHANNELS_IMG)],\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    batch_size = BATCH_SIZES[int(log2(image_size / 4))]\n",
        "    dataset = datasets.ImageFolder(root=DATASET, transform=transform)\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    return loader, dataset\n",
        "\n",
        "\n",
        "def train_fn(\n",
        "    critic,\n",
        "    gen,\n",
        "    loader,\n",
        "    dataset,\n",
        "    step,\n",
        "    alpha,\n",
        "    opt_critic,\n",
        "    opt_gen,\n",
        "    tensorboard_step,\n",
        "    writer,\n",
        "    scaler_gen,\n",
        "    scaler_critic,\n",
        "):\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch_idx, (real, _) in enumerate(loop):\n",
        "        real = real.to(DEVICE)\n",
        "        cur_batch_size = real.shape[0]\n",
        "\n",
        "        # Train Critic: max E[critic(real)] - E[critic(fake)] <-> min -E[critic(real)] + E[critic(fake)]\n",
        "        # which is equivalent to minimizing the negative of the expression\n",
        "        noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(noise, alpha, step)\n",
        "            critic_real = critic(real, alpha, step)\n",
        "            critic_fake = critic(fake.detach(), alpha, step)\n",
        "            gp = gradient_penalty(critic, real, fake, alpha, step, device=DEVICE)\n",
        "            loss_critic = (\n",
        "                -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
        "                + LAMBDA_GP * gp\n",
        "                + (0.001 * torch.mean(critic_real ** 2))\n",
        "            )\n",
        "\n",
        "        opt_critic.zero_grad()\n",
        "        scaler_critic.scale(loss_critic).backward()\n",
        "        scaler_critic.step(opt_critic)\n",
        "        scaler_critic.update()\n",
        "\n",
        "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
        "        with torch.cuda.amp.autocast():\n",
        "            gen_fake = critic(fake, alpha, step)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        scaler_gen.scale(loss_gen).backward()\n",
        "        scaler_gen.step(opt_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        # Update alpha and ensure less than 1\n",
        "        alpha += cur_batch_size / (\n",
        "            (PROGRESSIVE_EPOCHS[step] * 0.5) * len(dataset)\n",
        "        )\n",
        "        alpha = min(alpha, 1)\n",
        "\n",
        "        if batch_idx % 500 == 0:\n",
        "            with torch.no_grad():\n",
        "                fixed_fakes = gen(FIXED_NOISE, alpha, step) * 0.5 + 0.5\n",
        "            plot_to_tensorboard(\n",
        "                writer,\n",
        "                loss_critic.item(),\n",
        "                loss_gen.item(),\n",
        "                real.detach(),\n",
        "                fixed_fakes.detach(),\n",
        "                tensorboard_step,\n",
        "            )\n",
        "            tensorboard_step += 1\n",
        "\n",
        "        loop.set_postfix(\n",
        "            gp=gp.item(),\n",
        "            loss_critic=loss_critic.item(),\n",
        "        )\n",
        "\n",
        "    return tensorboard_step, alpha\n",
        "\n",
        "\n",
        "def main():\n",
        "    # initialize gen and disc, note: discriminator should be called critic,\n",
        "    # according to WGAN paper (since it no longer outputs between [0, 1])\n",
        "    # but really who cares..\n",
        "    gen = Generator(\n",
        "        Z_DIM, IN_CHANNELS, img_channels=CHANNELS_IMG\n",
        "    ).to(DEVICE)\n",
        "    critic = Discriminator(\n",
        "        Z_DIM, IN_CHANNELS, img_channels=CHANNELS_IMG\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # initialize optimizers and scalers for FP16 training\n",
        "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
        "    opt_critic = optim.Adam(\n",
        "        critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99)\n",
        "    )\n",
        "    scaler_critic = torch.cuda.amp.GradScaler()\n",
        "    scaler_gen = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # for tensorboard plotting\n",
        "    writer = SummaryWriter(f\"logs/gan1\")\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN, gen, opt_gen,LEARNING_RATE,\n",
        "        )\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC, critic, opt_critic,LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    gen.train()\n",
        "    critic.train()\n",
        "\n",
        "    tensorboard_step = 0\n",
        "    # start at step that corresponds to img size that we set in config\n",
        "    step = int(log2(START_TRAIN_AT_IMG_SIZE / 4))\n",
        "    for num_epochs in PROGRESSIVE_EPOCHS[step:]:\n",
        "        alpha = 1e-5  # start with very low alpha\n",
        "        loader, dataset = get_loader(4 * 2 ** step)  # 4->0, 8->1, 16->2, 32->3, 64 -> 4\n",
        "        print(f\"Current image size: {4 * 2 ** step}\")\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "            tensorboard_step, alpha = train_fn(\n",
        "                critic,\n",
        "                gen,\n",
        "                loader,\n",
        "                dataset,\n",
        "                step,\n",
        "                alpha,\n",
        "                opt_critic,\n",
        "                opt_gen,\n",
        "                tensorboard_step,\n",
        "                writer,\n",
        "                scaler_gen,\n",
        "                scaler_critic,\n",
        "            )\n",
        "            save_generated_images(epoch, gen, FIXED_NOISE, sav_dir, step)\n",
        "\n",
        "            if SAVE_MODEL:\n",
        "                save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
        "                save_checkpoint(critic, opt_critic, filename=CHECKPOINT_CRITIC)\n",
        "\n",
        "        step += 1  # progress to the next img size\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMqiWuv2tg4e",
        "outputId": "074f5ff6-dba4-41bd-a11d-2e19705be6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current image size: 256\n",
            "Epoch [1/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [08:17<00:00,  1.58s/it, gp=0.28, loss_critic=-.79]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [2/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:54<00:00,  1.32s/it, gp=0.00905, loss_critic=-3.3]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [3/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:54<00:00,  1.32s/it, gp=0.178, loss_critic=11.8]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [4/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:54<00:00,  1.32s/it, gp=1.74, loss_critic=-169]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [5/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:54<00:00,  1.32s/it, gp=0.00228, loss_critic=3.76]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [6/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.622, loss_critic=107]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [7/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.00918, loss_critic=-19.3]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [8/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0236, loss_critic=5.34]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [9/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.134, loss_critic=-26.4]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [10/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0122, loss_critic=5.76]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [11/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0596, loss_critic=-1.78]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [12/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.00253, loss_critic=-50.5]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [13/30]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.155, loss_critic=4.11]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [14/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:52<00:00,  1.31s/it, gp=0.0158, loss_critic=-.128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [15/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0966, loss_critic=13.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [16/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:52<00:00,  1.31s/it, gp=0.102, loss_critic=5.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [17/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0057, loss_critic=-.943]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [18/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.00772, loss_critic=-6.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [19/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.00139, loss_critic=-25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [20/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.129, loss_critic=-13.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [21/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0315, loss_critic=17.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [22/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.379, loss_critic=-40.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [23/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0612, loss_critic=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [24/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.103, loss_critic=92.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [25/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.125, loss_critic=6.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [26/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 315/315 [06:53<00:00,  1.31s/it, gp=0.0248, loss_critic=-18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "=> Saving checkpoint\n",
            "Epoch [27/30]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 80/315 [01:45<05:06,  1.31s/it, gp=0.0564, loss_critic=26.8]"
          ]
        }
      ]
    }
  ]
}